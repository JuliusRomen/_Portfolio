---


---

<h2 id="unicode.-кодировка-символов">Unicode. Кодировка символов</h2>
<p>Содержание статьи:</p>
<ul>
<li><strong>Введение</strong></li>
<li><strong>Рассвет стандартизации</strong></li>
<li><strong>UTF-8</strong></li>
<li><strong>UTF-16</strong></li>
<li><strong>UTF-32</strong></li>
<li><strong>Нормализация</strong></li>
<li><strong>Пара слов о пробелах</strong></li>
<li><strong>Заключение</strong></li>
</ul>
<h2 id="введение">ВВЕДЕНИЕ</h2>
<p align="justify"> <i>Кодировка</i> – это способ представления в памяти компьютера различных символов. Это могут быть как буквы различных письменностей, цифры, диакритические знаки, пробелы, так и графические, математические символы, эмодзи, стрелки, и т.д.
</p><p align="justify">Компьютер на самом низком уровне хранит информацию, и оперирует ей в двоичном виде. То есть, в виде последовательности единиц и нулей ( 1, 0). И изначально были разработаны однобайтовые кодировки символов, и в частности ASCII. Она позволяла кодировать символы в виде последовательности из 8 бит, и могла вместить в себя 2в8 = 256 символов.
</p><p align="justify">Первые 128 позиций этой кодировки занимают символы латинского алфавита, грамматические символы, а также специализированные символы управления, такие как табуляция и перенос текста. А вот оставшиеся биты можно было занять символами национальных языков, встречающихся только в них.
</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/4/4f/ASCII_Code_Chart.svg" alt="Таблица символов ASCII"></p>
<p align="justify">Таким образом, получается таблица, в которой у каждого символа есть адрес в шестнадцатеричной системе счисления, начиная от 00 до 7F  (от 00000000 до 01111111 в двоичной). И остается свободное пространство для национальных символов от 80 до FF (10000000 до 11111111).
</p><p align="justify">Попробуем закодировать слово «Hi» при помощи таблицы символов ASCII. Букве «H» соответствует шестнадцатеричное число 48. Переведя в двоичную систему счисления мы получим 48 = 01001000. Букве «i» соответствует число 69 = 01101001. Закодировав слово «Hi» мы получим последовательность 01001000 01101001. Также можно провести декодирование, переведя двоичное число в шестнадцатеричную систему, и по таблице найти соответствующий символ.
</p><p align="justify">В то время особо не задумывались о том, чтобы привести кодировки к единому стандарту. Поэтому для каждого языка существовала своя кодировка, которая была обратно совместима с ASCII. Например, для русского языка существовали кодировки КОИ-8, Windows-1251.
</p><p align="justify"><i>Обратная совместимость</i> означает, что текст, закодированный при помощи ASCII  прекрасно переводился и в КОИ-8, и в Windows-1251, Потому что первые 128 символов этих кодировок были идентичны друг другу.
</p><p align="justify">Путаница началась из-за того, что в кодировках разных языков разные национальные символы занимали одни и те же адреса. Представим себе такую ситуацию:
</p><p align="justify">На нашем компьютере мы используем кодировку КОИ-8. Мы пишем нашему другу из Западной Европы следующий текст:
</p><p align="center">Передаю тебе пламенный привет из России, мой милый друг!
</p><p align="justify">Сохраняем файл и отправляем его нашему старому приятелю. Он открывает его на своем компьютере, и видит следующее:
</p><p align="center">ðÅÒÅÄÁÀ ÔÅÂÅ ÐÌÁÍÅÎÎÙÊ ÐÒÉ×ÅÔ ÉÚ òÏÓÓÉÉ, ÍÏÊ ÍÉÌÙÊ ÄÒÕÇ!
</p><p align="justify">Мягко говоря, неприятная ситуация. Так могло случиться, только если его компьютер поддерживает кодировку Windows-1252.
</p><p align="justify">В ней символ ð хранится в виде F016 = 111100002. Также как и русский символ П в кодировке КОИ-8.
</p><p align="justify">Стало ясно, что необходимо привести кодировки к единому стандарту, чтобы избежать проблем. А ведь еще были языки Восточной Азии, использующие иероглифы для письменности. Для них тоже существовали ASCII-совместимые кодировки, но они использовали некоторые упрощения, потому что такая кодировка не смогла бы вместить  в себя даже самую малую часть существующих иероглифов. Началась разработка единого стандарта кодирования.
</p><h2 id="рассвет-стандартизации">РАССВЕТ СТАНДАРТИЗАЦИИ</h2>
<p align="justify"><i>Юникод</i> – это стандарт, описывающий принципы универсального кодирования символов. В этом стандарте существуют юникод-кодировки, имеющие разный формат кодирования (например, UTF-8, UTF-16, UTF-32).
</p><p align="justify">Что же отличает Юникод от своих предшественников?
</p><p align="justify">Юникод призван объединить все известные мировые символы единым стандартом, и обеспечить их доступность в любой точке мира.
</p><p align="justify">Стандарт Юникод вводит такое понятие как <i>Юникод-символ</i>, или <i>кодовая точка</i>. Он записывается в виде шестнадцатеричного числа от 0 до 10FFFF  с приставкой  «U+» . Например, букве «П» будет соответствовать юникод-символ U+041F.
</p><p align="justify">Таблица символов Юникода содержит все используемые символы, и соответствующие им юникод-символы. Всего в этой таблице имеется 1 114 112 позиций, но занята символами лишь малая часть. Большая часть таблицы сейчас свободна, поэтому считается, что в ближайшее время она не потребует расширения. Вся таблица разделена на 17 блоков, пронумерованных от нуля до шестнадцати. Каждый блок содержит в себе 65 536 позиций для символов. Блоки заполняются не случайным образом, а объединены некоторыми группами. Так, например, нулевой блок содержит в себе базовые и наиболее часто используемые символы всех алфавитов. Далее идет блок с символами вымерших языков, эмодзи. Следующий блок содержит в себе менее распространенные китайские иероглифы. Следующее пространство остается свободным, за исключением некоторых символов форматирования в 14 блоке. 15 и 16 блок выделены под приватное использование.
</p><p align="justify">Первые 128 символов юникод имеют такой же адрес, как и символы ASCII, то есть кодируются одним байтом. Это позволяет конвертировать ASCII-символы в Юникод без проблем и потерь.
</p><p align="justify">Но последующие символы будут занимать уже больше места, ведь таблица юникод содержит 1 114 112  позиций, и для кодирования символов старших блоков необходимо будет 2, 3, или 4 байта, но не более. Чтобы с этим разобраться, нужно понять, какие существуют юникод-кодировки, и как они кодируют символы.
</p><h2 id="utf-8">UTF-8</h2>
<p align="justify">Это юникод-кодировка, в которой символы имеют переменный размер. То есть, мы может закодировать их при помощи 1, 2, 3, 4 байтов.
</p><p align="justify">Первые 256 символов юникод представляются в виде однобайтового числа. Если мы вспомним таблицу ASCII, то заметим, что все числа там имеют в старшем бите 0, например как в слове «Hi» - 01001000 01101001. При кодировании при помощи UTF-8, если в байтовом числе старший бит имеет 0, то кодируем символ одним байтом. Далее идут символы, которые кодируются двумя байтами, такие символы всегда будут иметь маску 11хххххх 10хххххх. Символы, кодируемые тремя байтами будут иметь маску 111хххххх 10хххххх 10хххххх. Четырехбайтовые символы – 1111хххх 10хххххх 10хххххх 10хххххх. Биты из битовой маски не используются при кодировании, а лишь показывают, сколько байт в одном символе.
</p><p align="justify">Таким образом, среди байтового массива мы можем легко определять границы символов по их битовой маске. Для примера взглянем на следующий текст, закодированный при помощи UTF-8:
</p><p align="center">01000111 11010000 10010011 11100010 10010010 10111100
</p><p align="justify">Посмотрим на старшие биты в каждом байте:
</p><p align="center"><b>0</b>1000111 <b>11</b>010000 <b>10</b>010011 <b>111</b>00010 <b>10</b>010010 <b>10</b>111100
</p><p align="justify">Применяя маску разделим эти байты на символы:
</p><p align="center">01000111  | 11010000 10010011 | 11100010 10010010 10111100
</p><p align="justify">Здесь закодировано три символа, если мы опустим битовую маску, а также старшие биты, содержащие нули, то получим:
</p><p align="center">1000111  10000010011  10010010111100
</p><p align="justify">Теперь можно перевести эти числа в шестнадцатеричную систему:
</p><p align="center">47 413 24BC
</p><p align="justify">Этим числам соответствуют юникод-символы U+0047, U+0413, U+24BC. Находим эти числа в таблице юникод-символов, и записываем закодированный текст:
</p><p align="center">GГⒼ
</p><p align="justify">Латинские буквы кодируются при помощи одного байта, кириллические буквы кодируются двумя байтами.
</p><h2 id="utf-16">UTF-16</h2>
<p align="justify">Эта кодировка также имеет переменную длину. Но в ней символы кодируются только двумя, или четыремя байтами, образуя <i>кодовые пары</i>. То есть, в UTF-16 для кодирования используются пары байтов. Можно закодировать символ одной, или двумя парами.
</p><p align="justify">Для кодирования символов, использующих одну пару понадобится 16 бит. Если мы посчитаем количество таких символов, то получим 2в16 = 65 536, что соответствует размеру базового блока юникод. Символы из нулевого базового блока кодируются одной парой, например:
</p><p align="center">Hi, мир
</p><p align="justify">Эти символы состоят в базовом блоке символов, поэтому мы можем закодировать их одной парой байтов. По таблице юникод символов это будет выглядеть как:
</p><p align="center">U+0048 U+0069 U+002C U+043C U+0438 U+0440
</p><p align="justify">Теперь выделим из этих символов шестнадцатеричные числа:
</p><p align="center">48 69 2C 43C 438  440
</p><p align="justify">Переводим в двоичную систему счисления:
</p><p align="center">1001000  1101001  101100  1000011110  10000111000  10001000000
</p><p align="justify">И дописываем нули в старший бит, чтобы двоичные числа образовали байтовые пары:
</p><p align="center">00000000 01001000 | 00000000 01101001 | 00000000 0101100 |  00000100 0011110 | 00000100 00111000 | 00000100 01000000
</p><p align="justify">Таким образом кодируются символы в диапазонах 0000…D7FF  и E000…FFFF.
</p><p align="justify">Но существуют и такие символы, которые имеют размер больше, чем два байта. Они кодируются при помощи двух кодовых пар, то есть четырех байт. Давайте посмотрим, как это работает.
</p><p align="justify">Ранее мы уже называли диапазон символов, которые можно закодировать при помощи одной пары. Оттуда исключен диапазон D800…DFFF. В этом пространстве содержатся так называемые суррогатные пары.
</p><p align="justify"><i>Суррогатная пара</i> – две кодовых пары, которые составляют четыре байта. Они используются для кодирования символов диапазона 10000…10FFFF. Рассмотрим алгоритм кодирования на примере эмодзи – «😀». Юникод-символ этого эмодзи – U+1F600. Он выходит за пределы базового диапазона, поэтому будем кодировать его при помощи четырех байт.
</p><p align="justify">Из кода символа вычитаем 10000. Это минимальное число кодируемого диапазона.
</p><p align="center">1F600 – 10000 = F600
</p><p align="justify">Переводим результат в 20-битное двоичное число:
</p><p align="center">0000111101 1000000000
</p><p align="justify">Теперь приведем получившееся число шестнадцатеричный вид, старшие 10 бит, и младшие 10 бит.
</p><p align="center">0000111101  = 003D
</p><p align="center">1000000000 = 0200
</p><p align="justify">К старшим 10 битам прибавляем число D800 (Начало диапазона суррогатных пар):
</p><p align="center">003D + D800 = D83D
</p><p align="justify">К младшим 10 битам прибавляем число DC00  ( Оно входит в диапазон суррогатных пар):
</p><p align="center">0200 + DC00 = DE00
</p><p align="justify">Результат приводим к двоичному виду:
</p><p align="center">11011000  00111101 11011110  00000000
</p><p align="justify">У нас получились две кодовые пары, занимающие 4 байта. Первые 6 бит каждой пары – это маска, указывающая лишь на то, что используется кодирование двумя суррогатными парами. Десятый бит справа указывает на порядок суррогата, если в нем находится 0 – это первая пара, если 1 – это вторая пара.
</p><p align="center"><b>110110</b><i>0</i>0  00111101 <b>110111</b><i>1</i>0  00000000
</p><p align="justify">Также можно перевести двоичный код обратно в юникод-символ. Для этого из кода отбрасываются первые 6 бит с каждой пары. Остается:
</p><p align="center">0000111101 1000000000 (F600)
</p><p align="justify">Прибавляем 1000016 и получаем:
</p><p align="center">1F600
</p><p align="justify">Что соответствует юникод-символу U+1F600.
</p><p align="justify">Суммируя выше сказанное о UTF-16. Двоичная последовательность разбивается на байтовые пары. Каждая байтовая пара переводится в шестнадцатеричное число. Если получилось число из диапазона суррогатных пар, значит перед нами символ, кодируемый при помощи четырех байт, или двух пар. Смотрим на его десятый бит, чтобы определить позицию данной пары, и декодируем символ по алгоритму. Символы из базового диапазона декодируются просто переводом в шестнадцатеричную систему.
</p><h2 id="utf-32">UTF-32</h2>
<p align="justify">Существует еще кодировка UTF-32. В ней символы имеют фиксированный размер 4 байта. Например, латинская буква «A» будет иметь закодированный вид:
</p><p align="center">00000000 00000000 00000000 01000001
</p><p align="justify">Как видно, ее двоичное число соответствует числам из UTF-8 и UTF-16. Разница лишь в том, что в UTF-8 это однобайтовое число 01000001, в UTF-16 это двухбайтовое число 00000000 01000001, а в кодировке UTF-32 размер этого символа составляет 4 байта, старшие байты заполнены нулями.
</p><p align="justify">Эта особенность юникода позволяет без труда конвертировать текст между этими кодировками.
</p><h2 id="нормализация">НОРМАЛИЗАЦИЯ</h2>
<p align="justify">Во многих языках мира существуют буквы, содержащие в себе знаки краткости, надстрочные точки и символы. В русском языке это буквы «ё», «й». Такие буквы можно записать как в виде одной композитной кодовой точки, так и в виде двух кодовых точек. Например, буква й может быть записана как в виде U+0419 («Й»), так и в виде U+0418 U+0306 («И» + символ краткости). Также бывают ситуации, когда нужно указать ударение над буквой, было бы неоправданно дублировать все символы, которые могут иметь ударение, их также можно записать в виде двух кодовых точек.
</p><p align="justify">Такие вариации создают проблему поиска и сравнивания. Некоторые программы будут воспринимать композитную и составную «Й» как совершенно разные символы, что может затруднить операции по сравнению, слов, их сортировке, поиску. Для того, чтобы решить эту проблему, существует нормализация.
</p><p align="justify">Нормализация – это приведение символов к единому виду. В стандарте юникод описаны Canonical и Compatibility нормализация.
</p><p align="justify">Canonical  как раз нужна для сравнения одинаковых символов с разными кодовыми точками, таких, как «Й».
</p><ul>
<li>
<p>Normalization Form D (NFD) — canonical-декомпозиция. Раскладывает композитные символы на простые символы, и их диакритические знаки.</p>
</li>
<li>
<p>Normalization Form C (NFC) — Собирает символы обратно.</p>
</li>
</ul>
<p align="justify">Compatibility  нужна для того, чтобы сравнивать символы с их аналогичными упрощениями, например, ¼, 1/4.
</p><ul>
<li>
<p>Normalization Form KD (NFKD) — compatibility-декомпозиция. Приводит символы к их аналогичным упрощениям.</p>
</li>
<li>
<p>Normalization Form KC (NFKC) — также операция, обратная декомпозиции.</p>
</li>
</ul>
<p align="justify">То есть для того, чтобы текст можно было легко сравнивать между собой, необходимо сначала его привести к единому виду, нормализовать.
</p><h2 id="пара-слов-о-пробелах">ПАРА СЛОВ О ПРОБЕЛАХ</h2>
<p align="justify">В стандарте юникод описаны два вида пробелов.
</p><p>Первый тип пробелов – это <em>межсловный пробел</em> (U+0020).</p>
<p align="justify">Его ширина может колебаться от половины ширины кегля, до его пятой части (Для шрифта Times  New  Roman  ширина пробела составит ¼).
</p><p>Второй тип – <em>неразрывный межсловный пробел</em> (U+00A0).</p>
<p align="justify">Он имеет такую же ширину, что и обычный. Его отличие заключается в том, что в месте его использования запрещен перенос строки.
</p><p align="justify">Неразрывный пробел необходим для того, чтобы сохранить красивый вид написанного текста, запретив переносить строку в таких случаях:
</p><ul>
<li>При использовании сокращений «и т.д.», «и т.п.», «до н.э.», «т.е.»</li>
<li>При написании Фамилий с инициалами</li>
<li>При написании адреса («ул. Строителей», «г. Москва»)</li>
<li>Число и счетное слово («22 в.», «10 тыс.»)</li>
<li>Число и единица измерения («12 В», «100 кОм»)</li>
</ul>
<p align="justify">Также желательно использование неразрывного пробела перед короткими словами, союзами («и», «а», «но»).
</p><h2 id="заключение">ЗАКЛЮЧЕНИЕ</h2>
<p align="justify">При выборе используемой кодировки необходимо учитывать, сколько потребуется памяти, из каких символов будет состоять текст.
</p><p align="justify">UTF-8 хорошо подходит для текстов, в которых преобладают ASCII-символы, занимающие один байт. Такой текст будет занимать меньше памяти, ведь используя UTF-16, или UTF-32 старшие биты будут просто заполнены нулями. Напротив, если применять UTF-8 для текстов, в которых преобладают символы из старших диапазонов, такие как азиатские иероглифы, то такой текст будет занимать катастрофически много памяти, кодируя иероглифы по три или более байт.
</p><p align="justify">UTF-16 подойдет для текстов, в которых много национальных символов (Кириллица, иероглифы, и т.п.). Так как занимающие в UTF-8 три и более байт символы высокого порядка в UTF-16 будут занимать два байта.
</p><p align="justify">UTF-32 занимает много памяти. Но позволяет легко вычислять длину строки, благодаря фиксированному размеру символа, а также использовать более производительные алгоритмы.
</p>
